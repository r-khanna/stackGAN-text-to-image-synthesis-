# -*- coding: utf-8 -*-
"""dataset.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1AoK4TliH2iDnmGKbLTjtv2PdaB12GMyl
"""

from __future__ import absolute_import
from __future__ import division
from __future__ import print_function
from __future__ import unicode_literals


import torch.utils.data as data
from PIL import Image
import PIL
import os
import os.path
import pickle
import random
import numpy as np
import pandas as pd

#from miscc.config import cfg


class TextDataset(data.Dataset):
    def __init__(self, data_dir, split='jpg', embedding_type='cnn-rnn',
                 imsize=64, transform=None, target_transform=None):

        self.transform = transform
        self.target_transform = target_transform
        self.imsize = imsize
        self.data = []
        self.data_dir = data_dir
        split_dir = os.path.join(data_dir, split)

        self.filenames = self.load_filenames(split_dir)
        # self.embeddings = self.load_embedding(split_dir, embedding_type)
        self.class_id = self.load_class_id(split_dir, len(self.filenames))
        # self.captions = self.load_all_captions()

    def get_img(self, img_path):
        img = Image.open(img_path).convert('RGB')
        width, height = img.size
        # if bbox is not None:
        #     R = int(np.maximum(bbox[2], bbox[3]) * 0.75)
        #     center_x = int((2 * bbox[0] + bbox[2]) / 2)
        #     center_y = int((2 * bbox[1] + bbox[3]) / 2)
        #     y1 = np.maximum(0, center_y - R)
        #     y2 = np.minimum(height, center_y + R)
        #     x1 = np.maximum(0, center_x - R)
        #     x2 = np.minimum(width, center_x + R)
        #     img = img.crop([x1, y1, x2, y2])
        load_size = int(self.imsize * 76 / 64)
        img = img.resize((load_size, load_size), PIL.Image.BILINEAR)
        if self.transform is not None:
            img = self.transform(img)
        return img

    # def load_bbox(self):
    #     data_dir = self.data_dir
    #     bbox_path = os.path.join(data_dir, 'CUB_200_2011/bounding_boxes.txt')
    #     df_bounding_boxes = pd.read_csv(bbox_path,
    #                                     delim_whitespace=True,
    #                                     header=None).astype(int)
    #     #
    #     filepath = os.path.join(data_dir, 'CUB_200_2011/images.txt')
    #     df_filenames = \
    #         pd.read_csv(filepath, delim_whitespace=True, header=None)
    #     filenames = df_filenames[1].tolist()
    #     print('Total filenames: ', len(filenames), filenames[0])
    #     #
    #     filename_bbox = {img_file[:-4]: [] for img_file in filenames}
    #     numImgs = len(filenames)
    #     for i in xrange(0, numImgs):
    #         # bbox = [x-left, y-top, width, height]
    #         bbox = df_bounding_boxes.iloc[i][1:].tolist()

    #         key = filenames[i][:-4]
    #         filename_bbox[key] = bbox
    #     #
    #     return filename_bbox

    # def load_all_captions(self):
    #     caption_dict = {}
    #     for key in self.filenames:
    #         caption_name = '%s/text/%s.txt' % (self.data_dir, key)
    #         captions = self.load_captions(caption_name)
    #         caption_dict[key] = captions
    #     return caption_dict
    
    def load_all_captions(self):
    caption_dict = {}
    filepath = os.path.join(data_dir, 'caption_id.csv')
    cap=pd.read_csv(filepath)
    for key in self.filenames:
        caption_dict[key] = cap['Caption'][cap['image_id']==key]
    return caption_dict

    # def load_captions(self, caption_name):
    #     cap_path = caption_name
    #     with open(cap_path, "r") as f:
    #         captions = f.read().decode('utf8').split('\n')
    #     captions = [cap.replace("\ufffd\ufffd", " ")
    #                 for cap in captions if len(cap) > 0]
    #     return captions

    def load_embedding(self, data_dir, embedding_type):
        if embedding_type == 'cnn-rnn':
            embedding_filename = '/char-CNN-RNN-embeddings.pickle'
        elif embedding_type == 'cnn-gru':
            embedding_filename = '/char-CNN-GRU-embeddings.pickle'
        elif embedding_type == 'skip-thought':
            embedding_filename = '/skip-thought-embeddings.pickle'

        with open(data_dir + embedding_filename, 'rb') as f:
            embeddings = pickle.load(f)
            embeddings = np.array(embeddings)
            # embedding_shape = [embeddings.shape[-1]]
            print('embeddings: ', embeddings.shape)
        return embeddings

    def load_class_id(self, data_dir, total_num):
        if os.path.isfile(data_dir + 'filenames.csv'):
            filepath=os.path.join(data_dir, 'filenames.csv')
            class_id=np.array(pd.read_csv(filepath)['image_label'])
        else:
            class_id = np.arange(total_num)
        return class_id

    def load_filenames(self, data_dir):
        filepath = os.path.join(data_dir, 'filenames.csv')
        filenames=np.array(pd.read_csv(filepath)['image_id'])
        return filenames

    def __getitem__(self, index):
        key = self.filenames[index]
        # cls_id = self.class_id[index]
        #
        # if self.bbox is not None:
        data_dir = '%s/jpg' % self.data_dir
        # else:
            # bbox = None
            # data_dir = self.data_dir

        # captions = self.captions[key]
        # embeddings = self.embeddings[index, :, :]
        img_name = '%s/image/%s.jpg' % (data_dir, key)
        img = self.get_img(img_name)

        # embedding_ix = random.randint(0, embeddings.shape[0]-1)
        # embedding = embeddings[embedding_ix, :]
        # if self.target_transform is not None:
        #     embedding = self.target_transform(embedding)
        # return img, embedding
        return img

    def __len__(self):
        return len(self.filenames)
